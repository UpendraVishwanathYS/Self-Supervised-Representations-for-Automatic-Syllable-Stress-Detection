# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ttw-6vcEGitfVq7gBJReSf_KZjwqj1Wk
"""

# Required libraries
import os
import glob
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras import optimizers, backend as K
from keras.utils import to_categorical
from keras.layers import Dense, Dropout, BatchNormalization, Input
from keras.models import Model
import torch
import torchaudio
from torch import nn
from torchsummary import summary
from transformers import Wav2Vec2Processor, Wav2Vec2Model, Wav2Vec2FeatureExtractor
import scipy.io
import statistics
from sklearn.metrics import f1_score, accuracy_score
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import argparse
import librosa
import random
from math import e

def encode(x):
    return 0 if x == 'P' else 1

def sampling(args):
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=0.004)
    return z_mean + K.exp(z_log_sigma) * epsilon

def normalization(feats, avg, std):
    feats = np.array(feats)
    if feats.shape != avg.shape or feats.shape != std.shape:
        raise ValueError("The shapes of avg and std must match feats.")
    normalized_feats = (feats - avg) / std
    return normalized_feats

def Dataloader(df, layer_number, type_):
    if not isinstance(df, pd.DataFrame):
        raise ValueError("Input `df` must be a pandas DataFrame")

    required_columns = ['Type', 'file_name', 'Feature_Vector', 'Label', 'Word']
    for col in required_columns:
        if col not in df.columns:
            raise ValueError(f"Missing required column: {col}")

    filtered_df = df[df['Type'] == type_].sort_values(by=['file_name'])

    if not isinstance(layer_number, int):
        raise TypeError("`layer_number` must be an integer")
    try:
        X = filtered_df['Feature_Vector'].to_numpy().squeeze(2)[:,layer_number,:]
    except IndexError:
        raise IndexError("The specified layer_number is out of bounds for the Feature_Vector array")

    y = filtered_df['Label'].apply(lambda x: encode(x)).to_numpy()

    w = filtered_df['Word'].to_numpy()
    return X, y, w

def calculate_accuracy(arr1, arr2):
    return np.mean(np.array(arr1) == np.array(arr2))

def feature_extraction_from_DataFrame(database_lang,file_name,model,feature_extractor,device,path_to_audio_files='./',save_features = False,path_to_save_features = './'):
    #x--------Extract features at auido level------------x
    sub_df = database_lang[database_lang['file_name'] == file_name]
    path_to_audio_file = glob.glob(f'{path_to_audio_files}/*/*/{file_name}.wav')[0]
    waveform, sample_rate = torchaudio.load(path_to_audio_file)
    waveform = waveform.to(device)
    y, sr = librosa.load(path_to_audio_file, sr=None)
    duration=librosa.get_duration(y=y, sr=sr)
    inputs = feature_extractor(waveform.squeeze(), sampling_rate=sample_rate, return_tensors="pt", padding=True)
    #inputs = {key: val.to(device) for key, val in inputs.items()}
    inputs = inputs['input_values']
    with torch.no_grad():
      features = model(inputs.to(device)).hidden_states
    features_np = np.array([hs.cpu().numpy() for hs in features])
    duration_per_frame = duration / features_np.shape[-2]
    #x--------------------------------------------------x
    def syllable_level_features(row):
        start_time = row['Start']
        end_time = row['End']
        start_frame_number = int(start_time / duration_per_frame)
        end_frame_number = int(end_time / duration_per_frame)
        initial_matrix_array_average = np.mean(features_np[:, :, start_frame_number:end_frame_number, :], axis=2)

        if save_features == True:
          file_name_parts = [str(row[col]) for col in database_lang.columns]
          npy_file_name = f"{'#'.join(file_name_parts)}.npy"
          npy_file_path = os.path.join(path_to_save_features, npy_file_name)
          np.save(npy_file_path, initial_matrix_array_average)
        return initial_matrix_array_average
    sub_df['Feature_Vector'] = sub_df.apply(syllable_level_features, axis=1)
    return sub_df

def plot_tsne(model, input_data, labels, model_name, layer_number, language, raw, perplexity, img_path):
    """
    Generate and save a t-SNE plots for Supervised embeddings (or) raw embeddings

    Parameters:
    - model: The Keras model from which to extract the layer output.
    - input_data: Input data for the model (e.g., test data).
    - labels: True labels corresponding to the input data.
    - model_name: Name of the model (for saving the plot).
    - layer_number: Index of the layer to extract output from (0-based).
    - language: Language used for naming the output files.
    - raw: set True for raw embeddings, else for DNN embeddings.
    - perplexity: t-SNE perplexity parameter.
    - img_path: Path where the image will be saved.
    """

    if not raw:
        output_layer = model.layers[-2].output
        new_model = Model(inputs=model.input, outputs=output_layer)
        output = new_model.predict(input_data)
        colors = ["red", "black"]
    else:
        output = input_data
        colors = ["blue", "green"]

    # Perform t-SNE transformation
    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=123, verbose=1)
    z = tsne.fit_transform(output)

    # Prepare the DataFrame for plotting
    df = pd.DataFrame({
        "y": labels,
        "comp-1": z[:, 0],
        "comp-2": z[:, 1]
    })

    # Create the plot
    plt.figure(figsize=(10, 8), dpi=1200)
    sns.scatterplot(x="comp-1", y="comp-2", hue="y", palette=colors, edgecolor='black', data=df)
    plt.title(f"t-SNE plot: W2V2_{model_name} - Layer {layer_number} - {language}")
    plt.xlabel('Component 1')
    plt.ylabel('Component 2')

    # Customize legend visibility
    plt.legend(title="Classes", loc='best', bbox_to_anchor=(1, 1))

    # Ensure the img_path directory exists
    os.makedirs(img_path, exist_ok=True)

    # Save the plot with a dynamic file name
    file_name = f"TSNE: W2V2_{model_name}_Layer:{layer_number}_Language:{language}_raw_{raw}_perplexity_{perplexity}.png"
    file_path = os.path.join(img_path, file_name)
    plt.savefig(file_path, bbox_inches="tight")
    plt.close()

    print(f"Plot saved to {file_path}")