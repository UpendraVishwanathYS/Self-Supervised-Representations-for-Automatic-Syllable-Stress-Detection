# -*- coding: utf-8 -*-
"""trainer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Lk3X81cb8dpAbSp-iSnnQRZQs4HSJH7
"""


from utils import *
from variational_autoencoder import VariationalAutoencoder
from dnn import DNN


class Trainer:
    def __init__(self, layer_number, language, model_name, final_database_lang, classification_model='VAE_DNN', checkpoint_path='./', epochs=50, batch_size=32):
        self.layer_number = layer_number
        self.language = language
        self.model_name = model_name.split('/')[-1]
        self.final_database_lang = final_database_lang
        self.classification_model = classification_model
        self.checkpoint_path = checkpoint_path
        self.epochs = epochs
        self.batch_size = batch_size

        self.xtrain1, self.ytrain1, self.wtrain1 = self.Dataloader('train')
        self.xtest1, self.ytest1, self.wtest1 = self.Dataloader('test')

        self.train_size = self.xtrain1.shape[0]
        self.avg_trainfeat1 = np.mean(self.xtrain1, axis=0)
        self.std_trainfeat1 = np.std(self.xtrain1, axis=0)

        self.xtest_ac = self.normalization(self.xtest1)
        self.xtrain1 = self.normalization(self.xtrain1)

        print(f"xtrain1 shape: {self.xtrain1.shape}")
        print(f"ytrain1 shape: {self.ytrain1.shape}")
        print(f"xtest1 shape: {self.xtest1.shape}")
        print(f"ytest1 shape: {self.ytest1.shape}")
        print(f"Train size: {self.train_size}")

        self.ytest_categorical = to_categorical(self.ytest1, num_classes=2)

    def Dataloader(self, type_):
        df = self.final_database_lang[self.final_database_lang['Type'] == type_]
        df = df.sort_values(by=['file_name'])
        X = np.array(df['Feature_Vector'].tolist())[:,self.layer_number, :, :].squeeze(1)
        y = np.array(df['Label'].apply(lambda x: 0 if x == 'P' else 1).to_numpy())
        w = np.array(df['Word'].to_numpy())
        return X, y, w
    
    def normalization(self, feats):
        return (feats - self.avg_trainfeat1) / self.std_trainfeat1

    def train(self):
        for j in range(0, 5):  # 5 folds
            xval_ac = self.xtrain1[(self.train_size * j) // 5 : (self.train_size * (j + 1)) // 5]
            yval_ac = self.ytrain1[(self.train_size * j) // 5 : (self.train_size * (j + 1)) // 5]
            xtra_ac = np.concatenate((self.xtrain1[: (self.train_size * j) // 5], self.xtrain1[((self.train_size * (j + 1)) // 5) :]), axis=0)
            ytra_ac = np.concatenate((self.ytrain1[: (self.train_size * j) // 5], self.ytrain1[((self.train_size * (j + 1)) // 5) :]), axis=0)

            best_model_name = f"Validation_Model:{self.model_name}_Layer:{self.layer_number}_Language:{self.language}_best_{self.classification_model}_model_overall.h5"
            save_model_path = self.checkpoint_path
            best_model_path = os.path.join(save_model_path, best_model_name)

            if self.classification_model == 'VAE_DNN':
                original_dim = int(self.xtrain1.shape[-1])
                vae = VariationalAutoencoder(original_dim)
                vae.compile_model()
                vae.fit(xtra_ac, ytra_ac, xval_ac, yval_ac, best_model_path,epochs=self.epochs, batch_size=self.batch_size)
                model_save = vae.get_model()
                val_loss = vae.evaluate(xval_ac, yval_ac)
                pred_output = vae.predict(self.xtest1, self.ytest1)[1]
                pred1_labels = vae.convert_function(pred_output)
            else:
                dnn = DNN(input_shape=self.xtrain1.shape[1])
                dnn.fit(xtra_ac, ytra_ac, xval_ac, yval_ac, best_model_path,epochs=self.epochs, batch_size=self.batch_size)
                pred_output = dnn.predict(self.xtest_ac)
                pred1_labels = np.where(pred_output > 0.5, 1, 0)
                model_save = dnn.get_model()
                val_loss = dnn.evaluate(self.xtest_ac, self.ytest1)


if __name__ == "__main__":
    try:
      parser = argparse.ArgumentParser(description='Process layer number, language, and model name.')
      parser.add_argument('--layer_number', type=int, required=True, help='Layer number to process')
      parser.add_argument('--language', type=str, required=True, help='Language code (e.g., GER)')
      parser.add_argument('--model_name', type=str, required=True, help='Name of the model (e.g., wav2vec2-base-960h)')
      parser.add_argument('--classification_model', type=str, required=True, help='Classification model (e.g., DNN)')
      args = parser.parse_args()

    except:
      layer_number = 1
      language = 'GER'
      model_name = 'wav2vec2-base-960h'
      classification_model = 'DNN'

    # Assume final_database_lang is already defined
    trainer = Trainer(layer_number=args.layer_number, language=args.language, model_name=args.model_name, final_database_lang=final_database_lang)
    trainer.train()