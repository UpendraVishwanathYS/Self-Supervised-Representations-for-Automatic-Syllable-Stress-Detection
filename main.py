# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HIUmJR26zl_aJKOjuPzkkAziTeWxjS4X
"""

from utils import *
from trainer import *

try:
  parser = argparse.ArgumentParser(description='Process layer number, language, and model name.')
  parser.add_argument('--layer_number', type=int, default=1, help='Layer number to process')
  parser.add_argument('--language', type=str, default='GER', help='Language code (e.g., GER)')
  parser.add_argument('--w2v2_model_name', type=str, default='wav2vec2-base-960h', help='Name of the model (e.g., wav2vec2-base-960h)')
  parser.add_argument('--classification_model', type=str, default='DNN', help='Classification model (e.g., DNN)')
  parser.add_argument('--wav_files_path_zip', type=str, default='/content/drive/MyDrive/ICASSP 2024/feature_extraction/wav/wav_final.zip', help='Path to the zip file containing audio files')
  parser.add_argument('--path_to_database', type=str, default='/content/drive/MyDrive/ICASSP 2024/feature_extraction/database.csv', help='Path to the database CSV file')
  parser.add_argument('--checkpoint_path', type=str, default='./', help='Path to the checkpoint directory')
  parser.add_argument('--epochs', type=int, default=5, help='Number of epochs')
  parser.add_argument('--batch_size', type=int, default=32, help='Batch size')
  args = parser.parse_args()

  # Extract arguments
  layer_number = args.layer_number
  language = args.language
  w2v2_model_name = args.w2v2_model_name
  classification_model = args.classification_model
  wav_files_path_zip = args.wav_files_path_zip
  path_to_database = args.path_to_database
  checkpoint_path = args.checkpoint_path
  epochs = args.epochs
  batch_size = args.batch_size
  !unzip "$wav_files_path_zip"

except:
  layer_number = 1
  language = 'GER'
  w2v2_model_name = 'wav2vec2-base-960h'
  classification_model = 'DNN'
  wav_files_path_zip = f'/content/drive/MyDrive/ICASSP 2024/feature_extraction/wav/wav_final.zip'
  !unzip "$wav_files_path_zip"
  path_to_database = '/content/drive/MyDrive/ICASSP 2024/feature_extraction/database.csv'
  classification_model='DNN'
  checkpoint_path='./'
  epochs=5
  batch_size=32

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#Load and process database:
database = pd.read_csv(path_to_database)
database_lang = database[database['Language']==language]
database_lang = database_lang.reset_index(drop=True)

#Load W2V2 model:
w2v2_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(f'facebook/{w2v2_model_name}',output_hidden_states=True)
w2v2_model = Wav2Vec2Model.from_pretrained(f'facebook/{w2v2_model_name}',output_hidden_states=True).to(device)


# Feature extraction:
results_list = []
unique_files = database_lang['file_name'].unique()
for file_name in unique_files:
    processed_df = feature_extraction_from_DataFrame(database_lang,file_name,path_to_audio_files='/content/wav_final',save_features = False,path_to_save_features = './',model=w2v2_model,feature_extractor = w2v2_feature_extractor,device=device)
    results_list.append(processed_df)
final_database = pd.concat(results_list, ignore_index=True)

#Train: Supervised model
trainer = Trainer(
    layer_number=layer_number,
    language=language,
    model_name=w2v2_model_name,
    final_database_lang=final_database,
    classification_model=classification_model,
    checkpoint_path=checkpoint_path,
    epochs=epochs,
    batch_size=batch_size
)
trainer.train()